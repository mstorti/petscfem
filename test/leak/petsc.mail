To: petsc-maint@mcs.anl.gov
cc:
Subject: Memory leak in 2.1.3 ?
MIME-Version: 1.0
Content-Type: multipart/mixed; boundary="----- =_aaaaaaaaaa0"
Content-ID: <12552.1033949010.0@spider>

------- =_aaaaaaaaaa0
Content-Type: text/plain; charset="us-ascii"
Content-ID: <12552.1033949010.1@spider>

Hi PETSc people!!

I'm writing a C++ Finite Element code based on PETSc since 1998
(http://minerva.ceride.gov.ar/petscfem), and I updated recently from
PETSc 2.0.24 to 2.1.3. Then, I detected the my code started to have a
memory leak symptom, i.e. as the time step pass the total memory
reported by `top', or reading the `/proc' filesystem starts to
grow. For a moderately large problem (say 10,000 elements) it starts
to grow at a rate of 100KB/iter so that in several hundred iterations
the memory is exhausted and the run breaks down.

I used a memory leak tracer (LeakTracer
http://www.andreasen.org/LeakTracer/) and I didn't found leaks in my
code. Also I run PETSc with -trmalloc -trdump flags (with BOPT=g_c++)
but didn't detect any leaks. Finally I wrote a small PETSc program
where I create a 1D cyclic matrix with a stencil of [-0.1 1 -0.1] of
size N=100000, and run it 200 iters. All PETSc objects (matrix A,
vectors x and b, SLES sles) are created and destroyed inside the
loop. I detected that when I link with 2.1.3 the RSS grows at a rate
of 3.2KB/iter while with 2.0.24 it grows at a rate of 0.15KB/iter. 

I think that what happens is that that there is not memory leak, but
PETSc logging has changed between versions (I read something about it
in the docs) and now the logging demands much more memory than before.

My questions:

1./ May PETSc logging make the RSS to grow as much as 100KB/iter?
(consider creation and destruction of several matrices and vectors per
iteration). 

2./ If yes: How can it be deactivated? I tried to deactivate
-DPETSC_USE_LOG in bmake/linux/variables, `GCXX_PETSCFLAGS', but there
where to much compilation errors. (I guess that option is no
more maintained.). 

3./ Any other ideas?

System: 
> Linux spider 2.4.2-2 #1 Sun Apr 8 20:41:30 EDT 2001 i686 unknown

GCC:  
> Reading specs from /usr/lib/gcc-lib/i386-redhat-linux/2.96/specs
> gcc version 2.96 20000731 (Red Hat Linux 7.1 2.96-81)

PETSc: 2.1.3

Finally, thanks for all your effort. I'm very happy to work with PETSc
and I enjoy working with it all days!!

Regards,

Mario


------- =_aaaaaaaaaa0
Content-Type: text/plain; name="leak.cpp"; charset="us-ascii"
Content-ID: <12552.1033949010.2@spider>

/*__INSERT_LICENSE__*/
// $Id: petsc.mail,v 1.1 2002/10/07 00:23:14 mstorti Exp $

#define _GNU_SOURCE

#include <cmath>
#include <cstdio>
#include <cstdlib>
#include <cassert>
#include <unistd.h>

#ifdef USE_OLD_PETSC_VERSION
#include <sles.h>
#else
#include <petscsles.h>
#endif

inline double drand() {  
  return ((double)(rand()))/((double)(RAND_MAX));
}

void print_memory_usage(void) {
  int ierr;
  static char *file=NULL,*line=NULL;
  int mem,mem_min,mem_max,mem_sum,mem_avrg;
  size_t n=0;
  assert(asprintf(&file,"/proc/%d/status",getpid()));
  FILE *fid = fopen(file,"r");
  while(1) {
    assert(getline(&line,&n,fid)!=-1);
    if (sscanf(line,"VmRSS: %d kB",&mem)) break;
  }
  fclose(fid);
  int size;
  MPI_Comm_size(PETSC_COMM_WORLD,&size);
  MPI_Allreduce(&mem,&mem_min,1,MPI_INT,MPI_MIN,PETSC_COMM_WORLD);
  MPI_Allreduce(&mem,&mem_max,1,MPI_INT,MPI_MAX,PETSC_COMM_WORLD);
  MPI_Allreduce(&mem,&mem_sum,1,MPI_INT,MPI_SUM,PETSC_COMM_WORLD);
  mem_avrg = int(ceil(double(mem_sum)/double(size)));
  PetscPrintf(PETSC_COMM_WORLD,
	      "[Memory usage(kB): min %d, max %d, avrg %d]\n",
	      mem_min,mem_max,mem_avrg);
}

//---:---<*>---:---<*>---:---<*>---:---<*>---:---<*>---:---<*>---: 
#undef __FUNC__
#define __FUNC__ "main"
int main(int argc,char **args) {

  PetscInitialize(&argc,&args,NULL,NULL);

  Mat A;
  Vec b,x;
  SLES sles;
  PC pc;
  KSP ksp;

  const int N=100000;
  double h = 1./double(N);
  
  int niter=200;

  for (int iter=0; iter<=niter; iter++) {
    print_memory_usage();
    int ierr = MatCreateMPIAIJ(PETSC_COMM_WORLD,N,N,N,N,
			       3,NULL,3,NULL,&A); CHKERRQ(ierr); 
    ierr = VecCreateMPI(PETSC_COMM_WORLD,N,N,&b); CHKERRQ(ierr); 
    ierr = VecDuplicate(b,&x); CHKERRQ(ierr); 

    ierr = SLESCreate(PETSC_COMM_WORLD,&sles); CHKERRQ(ierr); 
    ierr = SLESGetKSP(sles,&ksp); CHKERRQ(ierr); 
    ierr = SLESGetPC(sles,&pc); CHKERRQ(ierr); 

    ierr = SLESSetOperators(sles,A,A,SAME_NONZERO_PATTERN); CHKERRQ(ierr); 
    ierr = KSPSetType(ksp,KSPCG); CHKERRQ(ierr); 
    ierr = PCSetType(pc,PCJACOBI); CHKERRQ(ierr); 

    for (int k=0; k<N; k++) {
      MatSetValue(A,k,k,1.,INSERT_VALUES); 
      
      int l=k+1;
      if (l>=N) l-=N;
      MatSetValue(A,k,l,-0.1,INSERT_VALUES); 
      
      l=k-1;
      if (l<0) l+=N;
      MatSetValue(A,k,l,-0.1,INSERT_VALUES); 
      VecSetValue(b,k,2.*drand()-1,INSERT_VALUES); 
    }
    ierr = VecAssemblyBegin(b);
    ierr = VecAssemblyEnd(b);
    
    ierr = MatAssemblyBegin(A,MAT_FINAL_ASSEMBLY); CHKERRQ(ierr); 
    ierr = MatAssemblyEnd(A,MAT_FINAL_ASSEMBLY); CHKERRQ(ierr); 
    
    int its;
    ierr = SLESSolve(sles,b,x,&its); CHKERRQ(ierr); 

    PetscPrintf(PETSC_COMM_WORLD,"iter %d, converged on %d CG iters\n",
		iter,its);
#if 0
    ierr = MatView(A,PETSC_VIEWER_STDOUT_WORLD); CHKERRQ(ierr); 
    ierr = VecView(x,PETSC_VIEWER_STDOUT_WORLD); CHKERRQ(ierr); 
#endif

    ierr = MatDestroy(A);
    ierr = VecDestroy(x);
    ierr = VecDestroy(b);
    ierr = SLESDestroy(sles);

  }
  PetscFinalize();
}

------- =_aaaaaaaaaa0
Content-Type: text/plain; name="Makefile"; charset="us-ascii"
Content-ID: <12552.1033949010.3@spider>

#__INSERT_LICENSE__
# $Id: petsc.mail,v 1.1 2002/10/07 00:23:14 mstorti Exp $ 

#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
ifeq (1,0)
CPPFLAGS += -DUSE_OLD_PETSC_VERSION
PETSC_DIR = $(HOME)/PETSC/petsc-2.0.24
include ${PETSC_DIR}/bmake/$(PETSC_ARCH)/base
#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
else
PETSC_DIR = $(HOME)/PETSC/petsc-2.1.3
include ${PETSC_DIR}/bmake/common/base
endif

BOPT=g_c++
LD_LIBRARY_PATH=$(PETSC_DIR)/lib/lib$(BOPT)/$(PETSC_ARCH)
LDFLAGS = -Wl,-E,-rpath,$(LD_LIBRARY_PATH) ${PETSC_SLES_LIB} -lc -lm -lg2c

leak.bin: leak.o
	-rm -f $@
	${CXX_CLINKER} -o $@ leak.o $(LDFLAGS)

------- =_aaaaaaaaaa0--
